apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "2"
    argocd.argoproj.io/sync-options: "SkipDryRunOnMissingResource=true"
    openshift.io/display-name: {{ .Values.inferenceService.name }}
    serving.knative.openshift.io/enablePassthrough: 'true'
    sidecar.istio.io/inject: 'true'
    sidecar.istio.io/rewriteAppHTTPProbers: 'true'
  name: {{ .Values.inferenceService.name }}
  labels:
    opendatahub.io/dashboard: 'true'
spec:
  predictor:
    maxReplicas: {{ .Values.inferenceService.maxReplicas }}
    minReplicas: {{ .Values.inferenceService.minReplicas }}
    {{- with .Values.inferenceService.affinity }}
    affinity:
      {{- toYaml . | nindent 6 }}
    {{- end }}
    {{- with .Values.inferenceService.tolerations }}
    tolerations:
      {{- toYaml . | nindent 6 }}
    {{- end }}
    initContainers:
      - name: model-downloader
        image: {{ .Values.model.downloader.image }}
        env:
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: huggingface-secret
                key: token
        volumeMounts:
          - mountPath: {{ .Values.model.storage.mountPath }}
            name: model-storage
        command:
          - "sh"
          - "-c"
          - |
            set -e

            REPO_ID="{{ .Values.model.repository }}"
            MOUNT_PATH="{{ .Values.model.storage.mountPath }}"

            echo "Installing huggingface_hub..."
            pip install huggingface_hub

            {{ range .Values.model.files }}
            TARGET_FILE="{{ . }}"
            TARGET_PATH="$MOUNT_PATH/$TARGET_FILE"

            if [ -e "$TARGET_PATH" ]; then
              echo "File '$TARGET_FILE' already exists at $TARGET_PATH. Skipping."
            else
              echo "Downloading '$TARGET_FILE' from repo $REPO_ID to $MOUNT_PATH..."

              hf download "$REPO_ID" "$TARGET_FILE" --local-dir "$MOUNT_PATH" --token "$HF_TOKEN"

              echo "Download of '$TARGET_FILE' complete."
            fi
            {{ end }}
    model:
      modelFormat:
        name: {{ .Values.servingRuntime.modelFormat }}
      {{- with .Values.inferenceService.resources }}
      resources:
        {{- toYaml . | nindent 8}}
      {{- end }}
      runtime: {{ .Values.servingRuntime.name }}
